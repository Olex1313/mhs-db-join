# db-homework-join

Реализуем утилиту для join-а 2 CSV-файлов.

В интерфейсе командной строки указываем

- имя "левого" файла
- номер поля "левого" файла, по которому будет join - начиная с 1
- имя "правого" файла
- номер поля "правого" файла, по которому будет join - начиная с 1
- тип join-а:  left, right, inner, outer

Например: 

```
join data1.csv 3 data2.csv 2 left  # left-join по 3 колонке data1.csv и data2.csv 
```

В выдачу идут все поля обоих таблиц в их исходном порядке. Сначала все поля первой,
потом - все поля второй. Независимо от того, по каким ключам был join.

Выдача печатается на консоль.

## Язык реализации и оформление

На выбор - C, C++, Java, Kotlin, Scala, Python, Go.

Если хочется на другом языке - спросите, можно ли.

Структура исходников - на ваше усмотрение.
Рекомендуется организовать в рамках традиций выбранного языка.
Например, gradle/maven в случае Java.

Без лишних усложнений. Если Java/Kotlin - без Spring.
Если Scala - не надо pure functional IO-фреймворков.
И Haskell не в перечне  - по тем же причинам.

И на любом языке - не нужно оверинжениринга и многослойных абстракций.
Чем проще, тем лучше.

Наша цель - поковырять руками алгоритм JOIN-а. Все лишние усложнения кода
будут нам только мешать в этом.

Дайте краткую инструкцию, как все собрать и запустить.

## Что гарантируется

csv-файл не содержит заголовков, переводов строк, экранирования символов и т.п.

Байтовый размер одной записи не превышает 1000 байт. 

Можно предполагать, что аргументы всегда корректны и особо их не проверять.

Пустых полей нет. По сути - нет большой разницы, интерпретировать ли join-ключи
как строки или как числа.

Размеры CVS-файла - не более 100Gb.


## Кеширование

Можно положиться на кеширование в файловой системе. Т.е. просто читать строчку за строчкой. 

Если сделаете свой кеш, никто вас за это не осудит.

##  Ограничения

Приложение не должно в итоге использовать больше, чем 4G памяти. И не обходить это ограничение через mmap и т.п.

## Как выглядит идеальное решение

Не падает ни при каких обстоятельствах.

В самом неблагоприятном варианте - когда переданы два файла размером по 100G и join-ключи совпадают, работает, не падая.
В таком сценарии время до выдачи первой записи результата должно составлять примерно время на работу `wc -l data1.csv data2.csv`, умноженное на небольшую константу.
И после первой записи выдача должна идти быстро и ритмично, без долгих залипаний. Скорее всего ни мне, ни вам не хватит терпения дождаться конца. Но корректная выдача должна идти.

В самом благоприятном сценарии - оба файла влезают в память - все файлы должны прочитаться по разу и сджойниться в памяти.

В особых случаях - например, если все ключи различаются в обоих файлах или один маленький, а другой большой - должен примениться оптимизированный сценарий.

В среднем случае - когда оба файла существенно не влезают в память, но "сцепки" по ключам - разумных размеров, должен быть применен алгоритм HashJoin или SortJoin. Выбор одного из них - на ваше усмотрение. 

И надо попытаться воспользоваться всеми возможностями оптимизаций. Не только теми, что я тут явно перечислил.

## Как тестировать

В целом - на ваше усмотрение.

В помощь прилагается исходник на питончике. Почему на нем ? Потому что lingua franca.

Там есть функции, которые дают неплохой базис для создания тест-кейсов. Их можно покомпоновать и организовать
cli-утилиту.

## Если вычислительных ресурсов мало

2 файла по 100G на входе, потенциально столько же места на резудьтаты первого прохода. 400G может не быть на диске.
И работать может медленно.

Если так - можете масштабировать в разы (в разумные разы).  Должно быть 2 прохода. И проход по времени - `t(wc -l data1.csv data2.csv) * c`.
Надо стремиться к этому ориентиру. И это не зависит от коэффициента. Но лучше все-таки проверять решение на объемах существенно больше доступной памяти.

## Что еще не надо

Не надо комитить IDE-проекты, тестовые файлы (особенно по 100G) и т.п.
